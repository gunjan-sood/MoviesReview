{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Review Data\n",
    "\n",
    "The problem contains the dataset which includes the movies review data with review as one column and the sentiment(positive or negative) associated with it in another column.\n",
    "\n",
    "The objective is to perform sentiment analysis on the reviews and build a model to do sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the positive and negative reviews dataset and merge them to create a new dataset with all the reviews. Mark all the negative reviews as 0 and positive reviews as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>simplistic , silly and tedious .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>it's so laddish and juvenile , only teenage bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>exploitative and largely devoid of the depth o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[garbus] discards the potential for pathologic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a visually flashy but narratively opaque and e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             review  sentiment_label\n",
       "0      0                  simplistic , silly and tedious .                 0\n",
       "1      1  it's so laddish and juvenile , only teenage bo...                0\n",
       "2      2  exploitative and largely devoid of the depth o...                0\n",
       "3      3  [garbus] discards the potential for pathologic...                0\n",
       "4      4  a visually flashy but narratively opaque and e...                0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the positive and negative reviews dataset and create a dataset with all the reviews\n",
    "\n",
    "neg = pd.read_csv('rt-polarity-neg.csv', sep='\\n', header=None, names=['review'])\n",
    "pos = pd.read_csv('rt-polarity-pos.csv', sep='\\n', header=None, names=['review'])\n",
    "neg['sentiment_label']=0\n",
    "pos['sentiment_label']=1\n",
    "reviews_df=neg.append(pos)\n",
    "reviews_df.reset_index(inplace=True)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "\n",
    "To understand the data, carry out some exploratory analysis: by checking the datatypes of the variables, size of the dataset and if there are any null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10662 entries, 0 to 10661\n",
      "Data columns (total 3 columns):\n",
      "index              10662 non-null int64\n",
      "review             10662 non-null object\n",
      "sentiment_label    10662 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 250.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the dataset\n",
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index              0\n",
       "review             0\n",
       "sentiment_label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are any missing values in the dataset\n",
    "reviews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove the index column from the dataset\n",
    "reviews_df.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simplistic , silly and tedious .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's so laddish and juvenile , only teenage bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exploitative and largely devoid of the depth o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[garbus] discards the potential for pathologic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a visually flashy but narratively opaque and e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment_label\n",
       "0                  simplistic , silly and tedious .                 0\n",
       "1  it's so laddish and juvenile , only teenage bo...                0\n",
       "2  exploitative and largely devoid of the depth o...                0\n",
       "3  [garbus] discards the potential for pathologic...                0\n",
       "4  a visually flashy but narratively opaque and e...                0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "Next, split the available dataset into training and test data with 10% of the total data assigned as the test dataset and remianing 90% as the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = reviews_df['review']\n",
    "y = reviews_df['sentiment_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create train and test dataset\n",
    "train_review_df = reviews_df.ix[X_train.index]\n",
    "test_review_df = reviews_df.ix[X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape (9595, 2)\n",
      "Test dataset shape (1067, 2)\n"
     ]
    }
   ],
   "source": [
    "print 'Training dataset shape',train_review_df.shape\n",
    "print 'Test dataset shape',test_review_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Import Natural language toolkit to clean the reviews by removing punctuations or numbers etc. Though punctuations may help to express the sentiments in some cases but not taking them into consideration for now. \n",
    "Import the stopwords list to remove all the stopwords from the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "# import the libraries \n",
    "\n",
    "import nltk # Import the stop word library from python Natural Language Toolkit\n",
    "nltk.download()\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "import re # Import regular expression library to find and replace the words\n",
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to convert uncleaned reviews to a string of reviews \n",
    "# 1. Remove non letters\n",
    "# 2. Change everything to lowercase\n",
    "# 3. Remove stopwords\n",
    "\n",
    "def cleanup_reviews(review):\n",
    "    letters = re.sub(\"[^a-zA-Z]\", \" \", review) # Remove anything in the sentence other than letters\n",
    "    words = letters.lower().split()   # change everything to lowercase\n",
    "    stops = set(stopwords.words(\"english\")) # convert to a set for faster processing\n",
    "    meaningful_words = [w.strip() for w in words if not w in stops]   # remove the stop words\n",
    "    sentence = \" \".join( meaningful_words )  # join back all the remaining words into sentence separated by a space\n",
    "    return sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply the cleanup_review function to all the reviews in the training dataset\n",
    "train_review_df['clean_review'] = train_review_df['review'].apply(cleanup_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the cleaned training dataset as a pickle\n",
    "train_review_df.to_pickle(\"cleaned_movie_reviews2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply the cleanup_review function to all the reviews in the test dataset\n",
    "test_review_df['clean_review'] = test_review_df['review'].apply(cleanup_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the cleaned test dataset as a pickle\n",
    "train_review_df.to_pickle(\"cleaned_movie_reviews2_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf \n",
    "\n",
    "Generate feature matrix using tf-idf vectorization based on term frequency and inverse document frequency instead of using the bag of words which simply counts the word frequency in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=3, max_df=0.95, max_features=900)\n",
    "train_data_features = vectorizer.fit_transform(train_review_df['clean_review'])\n",
    "test_data_features = vectorizer.fit_transform(test_review_df['clean_review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the feature matrix has been created, apply different machine learning models to it and check the model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest Classifier\n",
    "\n",
    "Train the model by fitting it in the training dataset and then making predictions on the unknown test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=200, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(train_data_features,train_review_df['sentiment_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions  = rfc.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation\n",
    "\n",
    "Check the model accuracy on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49203373945641987"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(test_data_features, test_review_df['sentiment_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[273 269]\n",
      " [273 252]]\n",
      "\n",
      "\n",
      "Classification_report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.50      0.50       542\n",
      "          1       0.48      0.48      0.48       525\n",
      "\n",
      "avg / total       0.49      0.49      0.49      1067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'Confusion Matrix'+'\\n\\n', confusion_matrix(test_review_df['sentiment_label'],predictions)\n",
    "print('\\n')\n",
    "print 'Classification_report'+'\\n\\n', classification_report(test_review_df['sentiment_label'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy obtained above is not high, hence trying to apply other models and check if they show any improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_model = mnb.fit(train_data_features,train_review_df['sentiment_label'])\n",
    "predictions_nb = nb_model.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[265 277]\n",
      " [256 269]]\n",
      "\n",
      "\n",
      "Classification_report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.49      0.50       542\n",
      "          1       0.49      0.51      0.50       525\n",
      "\n",
      "avg / total       0.50      0.50      0.50      1067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'Confusion Matrix'+'\\n\\n', confusion_matrix(test_review_df['sentiment_label'],predictions_nb)\n",
    "print('\\n')\n",
    "print 'Classification_report'+'\\n\\n', classification_report(test_review_df['sentiment_label'],predictions_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn =  KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(train_data_features,train_review_df['sentiment_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_knn = knn.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[354 188]\n",
      " [350 175]]\n",
      "\n",
      "\n",
      "Classification_report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.65      0.57       542\n",
      "          1       0.48      0.33      0.39       525\n",
      "\n",
      "avg / total       0.49      0.50      0.48      1067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'Confusion Matrix'+'\\n\\n', confusion_matrix(test_review_df['sentiment_label'],predictions_knn)\n",
    "print('\\n')\n",
    "print 'Classification_report'+'\\n\\n', classification_report(test_review_df['sentiment_label'],predictions_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_data_features,train_review_df['sentiment_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_lr = lr.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[271 271]\n",
      " [270 255]]\n",
      "\n",
      "\n",
      "Classification_report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.50      0.50       542\n",
      "          1       0.48      0.49      0.49       525\n",
      "\n",
      "avg / total       0.49      0.49      0.49      1067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'Confusion Matrix'+'\\n\\n', confusion_matrix(test_review_df['sentiment_label'],predictions_lr)\n",
    "print('\\n')\n",
    "print 'Classification_report'+'\\n\\n', classification_report(test_review_df['sentiment_label'],predictions_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
